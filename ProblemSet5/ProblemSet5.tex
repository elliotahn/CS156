\documentclass[12pt]{article}
\usepackage{amsmath,amssymb,amsthm}
\usepackage[margin=1in]{geometry}
\usepackage{graphicx,enumitem}
\usepackage{tikz,fancyhdr}
\usepackage[labelfont=bf]{caption}

\pagestyle{fancy}
\fancyhf{}
\chead{PROBLEM SET 5}
\rhead{Elliot Ahn}
\lhead{Machine Learning}
\rfoot{\thepage}

\setlength{\headheight}{15pt}
\renewcommand{\footrulewidth}{0.5pt}

\begin{document}

\begin{enumerate}[leftmargin=*]
\item (c) We solve
\begin{align*}
0.008 &\leq 0.1^2 \left( 1 - \frac{8 + 1}{N} \right) \\
N & \geq \frac{1 + 8}{1 - 0.008 / 0.1^2} = 45
\end{align*}
\item (d) This is a hyperbola, and because we want -1 in $\mathcal X$ space as $x_1 \to \infty$, it follows that $w_1 < 0$.
\item (c) 14th order space in the non-linear space, so our VC dimension is 14.
\item (e) Just take the derivative.
\item (d) We get 10 iterations to reach $E_{\text{in}} < 10^{-14}$.
\item (e) We get (0.0447, 0.024)
\item (a) Using the two-step method sucks because you're not going in the optimal direction.
\item (d) I got 0.108
\item (a) I got 340 average
\item (e) The PLA takes the update
\[ \mathbf w + y_n \mathbf x_n \to \mathbf w \]
Thus when performing SGD on point $n$, it follows that 
\[ \nabla e_n(\mathbf w) = - y_n \mathbf x_n \]
so 
\[ e_n(\mathbf w) = - y_n \mathbf w^T \mathbf x_n \]
However, we only perform this weight update if point $n$ has an error. Thus we have
\[ e_n(\mathbf w) = - \min(0, y_n \mathbf w^T \mathbf x_n). \]
\end{enumerate}

\end{document}